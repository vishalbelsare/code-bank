{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Recognition**: Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:  [https://github.com/d-insight/code-bank.git](https://github.com/d-insight/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we will perform a common image classification task, using the MNIST dataset. We consider a dataset of hand-written images and we are going to predict the number associated with each image. Every image has a dimension of 28 * 28 pixels and is gray-scale. The input data includes the intensity associated with each pixel row by row, starting from top-left corner (784 pixels in total). The label field shows the number associated with each image. \n",
    "\n",
    "The state-of-the-art model achieves an error rate of only 0.23% (Ciresan et al. CVPR 2012). We will achieve an approximate error rate of 1.2% in this demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png\" width=\"700\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Image source: https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an interactive hand-written image classification demo, visit: https://mnist-demo.herokuapp.com/ \n",
    "\n",
    "Dataset source: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 0**: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all import statements at the top of your notebook\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Data science packages\n",
    "from sklearn.model_selection import learning_curve, validation_curve, StratifiedShuffleSplit, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics         import confusion_matrix\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.dummy           import DummyClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from xgboost                 import XGBClassifier\n",
    "\n",
    "# Neural networks\n",
    "from tensorflow.keras.models                 import Sequential\n",
    "from tensorflow.keras.layers                 import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.models                 import Sequential\n",
    "from tensorflow.keras.layers                 import Dense\n",
    "from tensorflow.python.keras.utils.np_utils  import to_categorical\n",
    "\n",
    "# Visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants \n",
    "SCORE    = 'accuracy'\n",
    "N_CORES  = -1  # use all cores available\n",
    "SEED     =  0\n",
    "N_SPLITS =  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(train_scores, cv_scores, x_data, scale='lin', title='', y_label='', x_label=''):\n",
    "    \"\"\"\n",
    "    Plot validation and learning curves \n",
    "    \n",
    "    Parameter: \n",
    "        train_scores : first element of what validation_curve() object from sklearn returns\n",
    "        cv_scores : second element of what validation_curve() object from sklearn returns\n",
    "        x_data (list) : tuning parameter range to plot on x axis \n",
    "        scale (str) : 'lin' or 'log' for linear or logarithmic scale\n",
    "        title (str) : plot title \n",
    "        y_label (str) : y label \n",
    "        x_label (str) : x label \n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    \"\"\"  \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    cv_scores_mean = np.mean(cv_scores, axis=1)\n",
    "    cv_scores_std = np.std(cv_scores, axis=1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    \n",
    "    plt.fill_between(x_data, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.2, color=\"r\", lw=lw)\n",
    "    plt.fill_between(x_data, cv_scores_mean - cv_scores_std, cv_scores_mean + cv_scores_std, alpha=0.2, color=\"g\", lw=lw)\n",
    "    \n",
    "    if (scale == 'lin'):\n",
    "        plt.plot(x_data, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "        plt.plot(x_data, cv_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    elif (scale == 'log'):\n",
    "        plt.semilogx(x_data, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "        plt.semilogx(x_data, cv_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    Print and plot the confusion matrix\n",
    "    \n",
    "    Parameter: \n",
    "        cm : confusion_matrix() object from sklearn\n",
    "        normalize (bool) : indicator that normalizes confusion matrix entries\n",
    "        title (str) : plot title \n",
    "        cmap : matplotlib color scheme \n",
    "        \n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    \"\"\"  \n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round (cm[i, j],2), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_learning_curve(train_scores, cv_scores, x_data, scale='lin', title='', y_label='', x_label=''):\n",
    "    \"\"\"\n",
    "    Plot learning curve for different data sizes \n",
    "    \n",
    "    Parameter: \n",
    "        train_scores : second element of what learning_curve() object from sklearn returns (training scores)\n",
    "        cv_scores : third element of what learning_curve() object from sklearn returns (CV scores)\n",
    "        x_data (list) : first element of what learning_curve() object from sklearn returns (train sizes)\n",
    "        scale (str) : 'lin' or 'log' for linear or logarithmic scale\n",
    "        title (str) : plot title \n",
    "        y_label (str) : y label \n",
    "        x_label (str) : x label \n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    \"\"\"  \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    cv_scores_mean = np.mean(cv_scores, axis=1)\n",
    "    cv_scores_std = np.std(cv_scores, axis=1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    \n",
    "    plt.fill_between(x_data, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.2, color=\"r\", lw=lw)\n",
    "    plt.fill_between(x_data, cv_scores_mean - cv_scores_std, cv_scores_mean + cv_scores_std, alpha=0.2, color=\"g\", lw=lw)\n",
    "    \n",
    "    if (scale == 'lin'):\n",
    "        plt.plot(x_data, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "        plt.plot(x_data, cv_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    elif (scale == 'log'):\n",
    "        plt.semilogx(x_data, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "        plt.semilogx(x_data, cv_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1**: Data Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a dataframe\n",
    "\n",
    "data = pd.read_csv('image_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate basic statistics of data\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing value, if any\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "\n",
    "target = data['label'].values.ravel()\n",
    "features = data.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features to be between 0 and 1\n",
    "\n",
    "features = features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of labels\n",
    "\n",
    "sns.countplot(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize values of feature and its visual representation for an arbitrary data point\n",
    "\n",
    "# Define a subplot with two rows and one column\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12,6))\n",
    "dp_id = 100\n",
    "\n",
    "# Plot features representation in 1D\n",
    "ax[0].plot(features[dp_id])\n",
    "ax[0].set_title('Unravelled image in format 784x1')\n",
    "print()\n",
    "\n",
    "# Plot features representation in 2D\n",
    "ax[1].imshow(features[dp_id].reshape(28,28), cmap='gray')\n",
    "ax[1].set_title('Corresponding image in original format 28x28')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**: Define Cross-Validation Schema and Dummy Classifier Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=SEED, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a baseline using dummy classifier\n",
    "# It enables you to define a basic classifier which apply simple strategies such as stratified\n",
    "# Stratified strategy predicts probability of belonging to positive class as percentage of positive cases\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='stratified', random_state = SEED)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "baseline_score = dummy_clf.score(X_test, y_test)\n",
    "print('Baseline accuracy: {}'.format(round(baseline_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3**: Prediction using Logistic Regression with Ridge regularization\n",
    "\n",
    "Note: For parameter `C` in `LogisticRegression`, smaller values specify stronger regularization.\n",
    "\n",
    "We follow the following steps to come up with a prediction model:\n",
    "\n",
    "1. We tune our model parameter(s) using cross-validation on training set.\n",
    "2. We fit the model with tuned parameter on training set.\n",
    "3. We evaluate performance of our model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = LogisticRegression(penalty='l2', n_jobs = N_CORES, multi_class='multinomial', solver='saga', random_state=SEED)\n",
    "\n",
    "# Define cross-validation schema for tuning\n",
    "cv_schema = StratifiedKFold(n_splits = N_SPLITS, shuffle=True, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune model against a single hyper parameter C using validation_curve function\n",
    "\n",
    "tuning_param = 'C'\n",
    "tuning_param_range = np.logspace(-5, 5, 5)\n",
    "\n",
    "train_scores_val, cv_scores_val = validation_curve(\n",
    "    model, X_train, y_train, param_name = tuning_param, param_range = tuning_param_range,\n",
    "    cv = cv_schema, scoring = SCORE, n_jobs = N_CORES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation curve\n",
    "plot_validation_curve(train_scores_val, cv_scores_val, tuning_param_range, scale='log',\n",
    "                      title='Validation curve: logistic regression', y_label='accuracy', x_label='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best value of the hyper parameter\n",
    "\n",
    "best_param_val = tuning_param_range[np.argmax(np.mean(cv_scores_val, axis=1))]\n",
    "print('Best C: {}'.format(best_param_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model with best hyper parameter and assess its performance on the test data\n",
    "lr_clf = LogisticRegression(C = best_param_val, n_jobs = N_CORES, multi_class='multinomial', solver='saga', random_state=SEED)\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_score = lr_clf.score(X_test, y_test)\n",
    "print('LR with Ridge accuracy: {}\\n'.format(round(lr_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 4**: Prediction using KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters, model and cv schema\n",
    "model     = KNeighborsClassifier(n_jobs = N_CORES)\n",
    "cv_schema = StratifiedKFold(n_splits = N_SPLITS, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tune model against a single hyper parameter\n",
    "\n",
    "tuning_param = 'n_neighbors'\n",
    "tuning_param_range = []\n",
    "for i in np.linspace(2.0, 10.0, 2):\n",
    "    tuning_param_range.append(int(i))\n",
    "\n",
    "train_scores_val, cv_scores_val = validation_curve(\n",
    "    model, X_train, y_train, param_name = tuning_param, param_range = tuning_param_range,\n",
    "    cv = cv_schema, scoring = SCORE, n_jobs = N_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation curve\n",
    "plot_validation_curve(train_scores_val, cv_scores_val, tuning_param_range, scale='lin', \n",
    "                      title='Validation curve: KNN', y_label='accuracy', x_label='n_neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best value of the hyper parameter\n",
    "\n",
    "best_param_val = tuning_param_range[np.argmax(np.mean(cv_scores_val, axis=1))]\n",
    "print('Best n_neighbors: {}'.format(best_param_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with best hyper parameter and assess its performance on test data\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = best_param_val, n_jobs = N_CORES)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "knn_score = knn_clf.score(X_test, y_test)\n",
    "print('KNN accuracy: {}'.format(round(knn_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 5**: Prediction using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters, model and cv schema\n",
    "model     = RandomForestClassifier(n_jobs = N_CORES)\n",
    "cv_schema = StratifiedKFold(n_splits = N_SPLITS, shuffle=True, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tune model against a single hyper parameter\n",
    "\n",
    "tuning_param = 'n_estimators'\n",
    "tuning_param_range = []\n",
    "for i in np.linspace(10.0, 150.0, 5):\n",
    "    tuning_param_range.append(int(i))\n",
    "\n",
    "train_scores_val, cv_scores_val = validation_curve(\n",
    "    model, X_train, y_train, param_name = tuning_param, param_range = tuning_param_range,\n",
    "    cv = cv_schema, scoring = SCORE, n_jobs = N_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation curve\n",
    "\n",
    "plot_validation_curve(train_scores_val, cv_scores_val, tuning_param_range, scale='lin', \n",
    "                      title='Validation curve: random forest', y_label='accuracy', x_label='n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best value of the hyper parameter\n",
    "\n",
    "best_param_val = tuning_param_range[np.argmax(np.mean(cv_scores_val, axis=1))]\n",
    "print('Best n_estimators: {}'.format(best_param_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with best hyper parameter and assess its performance on test data\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = best_param_val, n_jobs = N_CORES)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_score = rf_clf.score(X_test,y_test)\n",
    "print('RF accuracy: {}'.format(round(rf_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 6**: Prediction using Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost library has a more performant implementation of gradient boosted trees\n",
    "model     = XGBClassifier(n_jobs = N_CORES, random_state = SEED)\n",
    "cv_schema = StratifiedKFold(n_splits = N_SPLITS, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tune model against a single hyper parameter\n",
    "tuning_param = 'n_estimators'\n",
    "tuning_param_range = []\n",
    "for i in np.linspace(30.0, 80.0, 10):\n",
    "    tuning_param_range.append(int(i))\n",
    "\n",
    "train_scores_val, cv_scores_val = validation_curve(\n",
    "    model, X_train, y_train, param_name = tuning_param, param_range = tuning_param_range,\n",
    "    cv = cv_schema, scoring = SCORE, n_jobs = N_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation curve\n",
    "plot_validation_curve(train_scores_val, cv_scores_val, tuning_param_range, scale='lin', \n",
    "                      title='Validation curve: gradient boosted trees', y_label='accuracy', x_label='n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best value of the hyper parameter\n",
    "best_param_val = tuning_param_range[np.argmax(np.mean(cv_scores_val, axis=1))]\n",
    "print('Best n_estimators: {}'.format(best_param_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with best hyper parameter and assess its perfrmance on test data\n",
    "\n",
    "gb_clf = XGBClassifier(n_estimators = best_param_val, n_jobs = N_CORES, random_state=SEED)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_score = gb_clf.score(X_test,y_test)\n",
    "print('Gradient boosted accuracy: {}'.format(round(gb_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 7**: Prediction using SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters, model and cv schema\n",
    "model     = SVC(random_state = SEED)\n",
    "cv_schema = StratifiedKFold(n_splits = N_SPLITS, shuffle=True, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tune model against a single hyper parameter\n",
    "\n",
    "tuning_param = 'C'\n",
    "tuning_param_range = np.logspace(-5, 5, 5)\n",
    "\n",
    "train_scores_val, cv_scores_val = validation_curve(\n",
    "    model, X_train, y_train, param_name = tuning_param, param_range = tuning_param_range,\n",
    "    cv = cv_schema, scoring = SCORE, n_jobs = N_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation curve\n",
    "\n",
    "plot_validation_curve(train_scores_val, cv_scores_val, tuning_param_range, scale='log', \n",
    "                      title='Validation curve: support vector classifier', y_label='accuracy', x_label='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best value of the hyper parameter\n",
    "\n",
    "best_param_val = tuning_param_range[np.argmax(np.mean(cv_scores_val, axis=1))]\n",
    "print('Best C: {}'.format(best_param_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with increasing amount of training data\n",
    "\n",
    "svc_clf = SVC(C = best_param_val)\n",
    "svc_clf.fit(X_train, y_train)\n",
    "svc_score = svc_clf.score(X_test,y_test)\n",
    "print('SVC accuracy: {}'.format(round(svc_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 8**: Prediction using Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels to one hot vectors (ex : 3 -> [0,0,0,1,0,0,0,0,0,0])\n",
    "\n",
    "y_train_ohe = to_categorical(y_train, num_classes = 10)\n",
    "y_test_ohe = to_categorical(y_test, num_classes = 10)\n",
    "y_train_ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters, model and cv schema\n",
    "\n",
    "epochs      = 10  # Number of iterations over full training set\n",
    "batch_size  = 200 # Number of observations to fit in every batch \n",
    "num_pixels  = 28 * 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile a simple feed forward neural network\n",
    "\n",
    "def ffnn_model():\n",
    "    \"\"\"\n",
    "    Set up a feed-forward neural network with two dense layers\n",
    "    \n",
    "    Parameter: \n",
    "        None\n",
    "    \n",
    "    Returns: \n",
    "        model : Keras Sequential() model \n",
    "        \n",
    "    \"\"\"  \n",
    "    \n",
    "    # Create a neural network with two dense layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ffnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize keras model\n",
    "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to data\n",
    "\n",
    "model.fit(X_train, y_train_ohe, validation_data = (X_test, y_test_ohe), \n",
    "          epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model on test set\n",
    "\n",
    "ff_loss, ff_score = model.evaluate(X_test, y_test_ohe)\n",
    "print()\n",
    "print('Loss (categorical cross-entropy):'.ljust(35) + str(round(ff_loss, 4)))\n",
    "print('Accuracy:'.ljust(35) + str(round(ff_score, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "\n",
    "# Get index of correctly and incorrectly classified observations\n",
    "target_val_orig = np.argmax(y_test_ohe, 1)\n",
    "\n",
    "# Get index list of all correctly predicted values\n",
    "correct_indices = np.nonzero(np.equal(predicted_classes, target_val_orig))[0]\n",
    "\n",
    "# Get index list of all incorrectly predicted values\n",
    "incorrect_indices = np.nonzero(np.not_equal(predicted_classes, target_val_orig))[0]\n",
    "\n",
    "# Print number of correctly and incorrectly clasified observations\n",
    "print ('Correctly predicted:'.ljust(30) + str(np.size(correct_indices)))\n",
    "print ('Incorrectly predicted:'.ljust(30) + str(np.size(incorrect_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a sample of incorrectly classified samples\n",
    "    \n",
    "plt.figure(figsize=[20,8])\n",
    "for i, incorrect in enumerate(incorrect_indices[:6]):\n",
    "    plt.subplot(1,6,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], target_val_orig[incorrect]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 9**: Prediction using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "\n",
    "X_train_reshaped = X_train.reshape(-1,28,28,1)\n",
    "X_test_reshaped = X_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a single pixel value in reshaped arrays\n",
    "\n",
    "X_train_reshaped[2800][27][27][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels to one hot vectors\n",
    "\n",
    "y_train_ohe = to_categorical(y_train, num_classes = 10)\n",
    "y_test_ohe  = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters, model and cv schema\n",
    "\n",
    "epochs     = 12  # number of iterations over full training set\n",
    "batch_size = 128 # number of observations to fit in every batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN architechture (architecture taken from:\n",
    "# https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "\n",
    "def cnn_model():\n",
    "    \"\"\"\n",
    "    Set up a convolutional neural network (architecture from: https://keras.io/examples/mnist_cnn/)\n",
    "    \n",
    "    Parameter: \n",
    "        None\n",
    "    \n",
    "    Returns: \n",
    "        model : Keras Sequential() model \n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return (model)\n",
    "\n",
    "model = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to data\n",
    "\n",
    "model.fit(X_train_reshaped, y_train_ohe, validation_data=(X_test_reshaped, y_test_ohe), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model on test set\n",
    "\n",
    "cnn_loss, cnn_score = model.evaluate(X_test_reshaped, y_test_ohe)\n",
    "print()\n",
    "print('Loss (categorical cross-entropy):'.ljust(35) + str(round(cnn_loss, 4)))\n",
    "print('Accuracy:'.ljust(35) + str(round(cnn_score, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "predicted_classes = model.predict_classes(X_test_reshaped)\n",
    "\n",
    "# Get index of correctly and incorrectly classified observations\n",
    "target_val_orig = np.argmax(y_test_ohe, 1)\n",
    "\n",
    "# Get index list of all correctly predicted values\n",
    "correct_indices = np.nonzero(np.equal(predicted_classes, target_val_orig))[0]\n",
    "\n",
    "# Get index list of all incorrectly predicted values\n",
    "incorrect_indices = np.nonzero(np.not_equal(predicted_classes, target_val_orig))[0]\n",
    "\n",
    "# Print number of correctly and incorrectly clasified observations\n",
    "print ('Correctly predicted:'.ljust(30) + str(np.size(correct_indices)))\n",
    "print ('Incorrectly predicted:'.ljust(30) + str(np.size(incorrect_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a sample of incorrectly classified samples\n",
    "    \n",
    "plt.figure(figsize=[20,8])\n",
    "for i, incorrect in enumerate(incorrect_indices[:6]):\n",
    "    plt.subplot(1,6,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], target_val_orig[incorrect]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix\n",
    "y_pred_ohe = model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred_ohe, axis = 1) \n",
    "y_true = np.argmax(y_test_ohe, axis = 1) \n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes) \n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SUMMARY OF ACCURACY SCORES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width    = 35\n",
    "models   = ['Baseline',     'LR + Ridge', 'KNN',     'Random Forest', 'Boosted Trees', 'SVC',     'NN',     'CNN']\n",
    "results  = [baseline_score, lr_score,     knn_score, rf_score,        gb_score,        svc_score, ff_score, cnn_score]\n",
    "\n",
    "print('', '=' * width, '\\n', 'Summary of Accuracy Scores'.center(width), '\\n', '=' * width)  \n",
    "for i in range(len(models)):\n",
    "    print(models[i].center(width-8), '{0:.4f}'.format(round(results[i], 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 10**: Investment into More Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning_curve function in sklearn.model_selection is used to assess performance of \n",
    "# a model with diferent training sizes, hence justifying possible investments\n",
    "# into gathering more data\n",
    "\n",
    "# Here we train random forest classifier with increasing amount of training data\n",
    "rf_clf      = RandomForestClassifier(n_estimators = 50, n_jobs = N_CORES)\n",
    "cv_schema   = StratifiedShuffleSplit(n_splits = N_SPLITS, test_size = 0.33, shuffle=True, random_state = SEED)\n",
    "train_sizes = np.linspace(.1, 1.0, 5)\n",
    "\n",
    "train_sizes, train_scores_learn, cv_scores_learn = learning_curve(\n",
    "        rf_clf, features, target, cv = cv_schema, n_jobs = N_CORES, train_sizes = train_sizes, scoring = SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "\n",
    "plot_learning_curve(train_scores_learn, cv_scores_learn, train_sizes, scale='lin', \n",
    "                      title='Learning curve: random forest', y_label='accuracy', x_label='train set size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 11**: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How can one justify the investment on gathering additional data ? \n",
    "* How much an accuracy equal to 99.99 % is more significant than one equal to 99.90 % ? \n",
    "* What about 99.90 % compared to 99.00 % ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
