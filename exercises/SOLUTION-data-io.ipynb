{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DSFM Exercise**: Data input, manipulation and output (SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creator: [Data Science for Managers - EPFL Program](https://www.dsfm.ch)  \n",
    "Source:  [https://github.com/dsfm-org/code-bank.git](https://github.com/dsfm-org/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise session, we will load data from a file, manipulate those data in Python and finally write it back to a file. These basic operations are important in any data science project. \n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a Python package built for data analysis. It includes many useful functions, including one to read comma-separated (.csv) files. We will use this package as it's both easy to use and very powerful.\n",
    "\n",
    "Firstly, we need to import Pandas. As you will be learning (or already know), popular Python packages have common abbreviates. These abbreviations are used as a short-hand for that package throughout a Python script. Some of these common abbreviations include:\n",
    "\n",
    "- `import pandas as pd`\n",
    "- `import numpy as np`\n",
    "- `import tensorflow as tf`\n",
    "- etc.\n",
    "\n",
    "Secondly, we can call any function in the Pandas package as `pd.someFunction`. The `pd` keyword is reserved for Pandas and must not be used by any other variable. \n",
    "\n",
    "Thirdly, `import` statements are generally located at the top of a script, even though they might only be used at a later stage.\n",
    "\n",
    "Finally, do not hesitate to search the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/) for help.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Loading .csv data\n",
    "\n",
    "In this part, we  load input data from a .csv file into this Jupyer notebook. This file contains courses offered at EPFL with the following two columns: \n",
    "\n",
    "- course: full course name\n",
    "- code: course code, including field of study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Load .csv data. What shape does it have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "EPFLcourses = pd.read_csv('data/epfl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the number of rows and columns (the shape)\n",
    "\n",
    "EPFLcourses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Look at the data shape, first 5 and last 5 rows. Can you draw a random sample from the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first 5 rows\n",
    "\n",
    "EPFLcourses.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the last 5 rows\n",
    "\n",
    "EPFLcourses.tail(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a random sample of 5 rows\n",
    "\n",
    "EPFLcourses.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Extract the course field\n",
    "\n",
    "In this part, we extract the field code (e.g. CS, EE, MATH) from the course code column. We then create a new column called `field`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Create a new column and fill it with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy column called 'field' filled with 0s\n",
    "\n",
    "EPFLcourses['field'] = 0\n",
    "EPFLcourses.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Fill the new column with the field of the course. What symbol do you split on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the 'field' column with the split code\n",
    "\n",
    "EPFLcourses['field'] = EPFLcourses['code'].str.split('-')\n",
    "EPFLcourses.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first list element (index 0) for each field entry\n",
    "\n",
    "EPFLcourses['field'] = EPFLcourses['field'].str[0]\n",
    "EPFLcourses.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Clean data\n",
    "\n",
    "In this part, we clean the dataset. We find missing fields and remove those entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Look at some examples where a value for `field` is missing. What's a course without a code/field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the entries without a field\n",
    "\n",
    "EPFLcourses[EPFLcourses['field'].isna()].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: How many rows are removed by dropping all rows without a value for `field`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the shape of data before removing missing values\n",
    "\n",
    "EPFLcourses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries without a description\n",
    "\n",
    "EPFLcourses = EPFLcourses.dropna(subset=['field'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after removing entries, inspect the shape of data again\n",
    "\n",
    "EPFLcourses.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81 rows have been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that entries were indeed removed\n",
    "\n",
    "EPFLcourses[EPFLcourses['field'].isna()].head(n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Count the number of courses in each field\n",
    "\n",
    "Let's find out how many courses EPFL offers in each field. For that, we can use Pandas' `.grouby()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Group the data by `field`. How many Architecture (AR) courses are offered at EPFL?\n",
    "\n",
    "Hint: use the `.agg('count')` function in Pandas. Be careful though, is the function robust to missing values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by field and count the number of course entries\n",
    "\n",
    "EPFLcourses_count = EPFLcourses[['course', 'field']].groupby('field').agg('count')\n",
    "EPFLcourses_count.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Sort the data in descending order by course count. What field has the most courses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the data in descending order to find out what the most common fields are\n",
    "\n",
    "EPFLcourses_count = EPFLcourses_count.sort_values(by='course', ascending = False)\n",
    "EPFLcourses_count.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Write data to disk\n",
    "\n",
    "In this part, we write the number of courses per field to disk as an Excel and comma separated (.csv) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Re-organize the Pandas dataframe such that it has two columns: field, course_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-organize the Pandas dataframe such that it has two columns: field, course_count\n",
    "\n",
    "EPFLcourses_count = EPFLcourses_count.reset_index()\n",
    "EPFLcourses_count.columns = ['field', 'course_count']\n",
    "EPFLcourses_count.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Write the data to an .xlsx and .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to .xlsx, without the index\n",
    "\n",
    "EPFLcourses_count.to_excel('data/epfl_output.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to .csv, without the index\n",
    "\n",
    "EPFLcourses_count.to_csv('data/epfl_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Load tab-separated plain text (.txt) file\n",
    "\n",
    "In the last part, we load in a plain text file where columns have been separated by a tab `\\t` symbol. This kind of data is typical for government data, such as the US Patent Office (USPTO). This file contains two columns:\n",
    "\n",
    "- id: patent sub-class id\n",
    "- title: patent sub-class title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Open the `USPTOsubclasses.txt` file with native Python and save it as a list of lists. What's the sub-class \"1/1\" called?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the .txt file\n",
    "\n",
    "textFile = open('data/USPTOsubclasses.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file and split it by the new line character \"\\n\"\n",
    "\n",
    "lines = textFile.read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of lists where each row is one line and each column is a tab-separated field\n",
    "\n",
    "list_of_lists = []\n",
    "\n",
    "for l in lines:\n",
    "    list_of_lists.append(l.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first 10 list elements\n",
    "\n",
    "list_of_lists[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Turn the data into a Pandas dataframe and draw a random sample of 5 rows. Hint: remember to split the header row from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pandas dataframe to facilitate data manipulation\n",
    "\n",
    "# the header is the first element in the list of lists\n",
    "header = list_of_lists[0]\n",
    "\n",
    "# the data are the remaining elements\n",
    "data = list_of_lists[1:]\n",
    "\n",
    "# create a dataframe for easy manipulation\n",
    "uspto = pd.DataFrame(data, columns=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the dataframe\n",
    "\n",
    "uspto.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
