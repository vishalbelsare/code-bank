{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Complex prediction**: Decision trees (SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:  [https://github.com/d-insight/code-bank.git](https://github.com/d-insight/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a classification tree and random forest model to the Boston dataset to predict crime per capita. We create a binary outcome feature, `CRIM_BIN`, that is equal to 1 if the crime rate contains a value above or equal to its median, and a 0 if the crime rate contains a value below its median. \n",
    "\n",
    "This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It based on Harrison and Rubinfeld (1978) data and a similar dataset is available [here](https://nowosad.github.io/spData/reference/boston.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from graphviz import Source\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constant(s)\n",
    "\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAIN EXERCISE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load data and create train/test sets\n",
    "\n",
    "In the first part, we load the `housing.csv` dataset. This dataset includes the following columns:\n",
    "\n",
    "- `CRIM`: per capita crime rate\n",
    "- `ZN`: proportions of residential land zoned for lots over 25000 sq. ft per town (constant for all Boston tracts)\n",
    "- `INDUS`: proportions of non-retail business acres per town (constant for all Boston tracts)\n",
    "- `CHAS`: levels 1 if tract borders Charles River; 0 otherwise\n",
    "- `NOX`: nitric oxides concentration (parts per 10 million) per town\n",
    "- `RM`: average numbers of rooms per dwelling\n",
    "- `AGE`: proportions of owner-occupied units built prior to 1940\n",
    "- `DIS`: weighted distances to five Boston employment centres\n",
    "- `RAD`: index of accessibility to radial highways per town (constant for all Boston tracts)\n",
    "- `TAX`: full-value property-tax rate per USD 10,000 per town (constant for all Boston tracts)\n",
    "- `PTRATIO`: pupil-teacher ratios per town (constant for all Boston tracts)\n",
    "- `B`: proportion of blacks\n",
    "- `LSTAT`: percentage values of lower status population\n",
    "- `MEDV`: median values of owner-occupied housing in USD 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Load the data. What shape does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "\n",
    "df = pd.read_csv('data/housing.csv', delim_whitespace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Create the binary feature `CRIM_BIN` that contains a 1 if `CRIM` contains a value above or equal to its median, and a 0 if `CRIM` contains a value below its median. What % are 1s? Is the target variable balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median of CRIM\n",
    "crim_med = df.median()['CRIM']\n",
    "\n",
    "# OPTION 1\n",
    "CRIM_BIN = (df['CRIM'] >= crim_med).astype(int)\n",
    "\n",
    "# OPTION 2\n",
    "# # extract values of CRIM into list\n",
    "# CRIM = df['CRIM'].values.tolist()\n",
    "# # compute values of CRIM_BIN\n",
    "# CRIM_BIN = []\n",
    "# for crim_value in CRIM:\n",
    "#     CRIM_BIN_value = int(crim_value >= crim_med)\n",
    "#     CRIM_BIN.append(CRIM_BIN_value)\n",
    "    \n",
    "# Add CRIM_BIN column to dataframe\n",
    "df['CRIM_BIN'] = CRIM_BIN\n",
    "\n",
    "# Display head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Split data into train/test sets and look at the descriptive statistics\n",
    "\n",
    "Before modeling the data, we perform the usual train/test split and look at how the descriptive statistics between the two sets compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Divide data into a training set (80%) and testing set (20%) randomly with a seed (we defined the seed as a constant at the very top of the notebook). The seed ensures that the random process returns the same results when ran multiple times. Next, split the training and testing data into the explanatory variables and the outcome variable. How can you ensure that samples are randomly assigned to the training or testing set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split data into train set (80%) and test set (20%)\n",
    "df_train, df_test = train_test_split(df, train_size = 0.8, test_size = 0.2, random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For both train and test data, extract CRIM_BIN column and combine relevant explanatory variables\n",
    "\n",
    "y_col   = 'CRIM_BIN'\n",
    "X_cols = ['ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "\n",
    "# Prepare data for classifier model (converts data frame to a list of lists)\n",
    "y_train = df_train[y_col]\n",
    "X_train = df_train[X_cols]\n",
    "\n",
    "y_test = df_test[y_col]\n",
    "X_test = df_test[X_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Look at the descriptive statistics for train/test sets. Are the distributions similar? What can we do if the distributions of the outcome variable (`CRIM_BIN`) are different? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute descriptive statistics for the training set\n",
    "\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the distributions for the outcome variable (`CRIM_BIN`) are different, we can stratify according to this variable. More specifically, we can set the `stratify` parameter of the `train_test_split()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fit a decision tree classifier\n",
    "\n",
    "A decision tree classifier is a simple, non-linear tree model. You find the sklearn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). This model represents our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Fit a decision tree and tune the `max_depth` parameter. Hint: use `sklearn.model_selection.GridSearchCV()` for parameter tuning and tune the `max_depth` parameter in the range `[1,14]`. What's the optimal depth of trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune max_depth parameter in the range (1,14)\n",
    "\n",
    "tuned_parameters = [{'max_depth': range(1,14)}]\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(random_state = SEED), tuned_parameters, cv = 5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Look at the best parameters\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the optimal tree depth\n",
    "\n",
    "best_tree_depth = clf.best_params_['max_depth']\n",
    "best_tree_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Assess the classifier on the test set. What accuracy do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing best performing classifier tree on test set\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth = best_tree_depth, random_state=SEED)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "y_pred = clf_tree.predict(X_test)\n",
    "\n",
    "acc_tree = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ' + str(acc_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ADVANCED EXERCISE**\n",
    "\n",
    "*Optional.* If time permits and you feel comfortable with Python, continue with the advanced parts of this exercise below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Plot the tree partitioning and feature importance\n",
    "\n",
    "This part tells us how the tree classifier partitions the feature space. In other words, we see which features are most informative (i.e. split at the root) and at what values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Plot the tree patitioning. What's the most informative feature?\n",
    "\n",
    "Hint 1: use the `export_graphviz()` function from the `graphviz` package to plot the tree.\n",
    "\n",
    "Hint 2: use the `Source` function from the `graphviz` package to create a graph that can be displayed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot best performing regression tree using graphviz\n",
    "#     this may not work on all computers - requires graphviz to be installed\n",
    "#     install graphviz on a Mac computer by running:  brew install -v graphviz\n",
    "#     install graphviz on Linux computer by running:  sudo apt-get install graphviz\n",
    "Source(export_graphviz(clf_tree, out_file=None, feature_names=X_cols, max_depth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Look at the feature importance on a histogram. Hint: use the `.feature_importances_` function in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and plot importance of explanatory features\n",
    "\n",
    "feat_names = ['ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "feat_importance = clf_tree.feature_importances_.tolist()\n",
    "\n",
    "plt.bar(list(range(1, len(feat_names)+1)), feat_importance, tick_label = feat_names, align = 'center')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Importance of Features for Classification Tree')\n",
    "plt.xlabel('explanatory features')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: NOX (nitric oxides concentration) is the best predictor. Does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Compute the ROC curve\n",
    "\n",
    "In this part, we compute the false positive rate, true positive rate and thresholds defining ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: What are the false positive and true rates? What's the area under the curve (AUC)?\n",
    "\n",
    "Hint: generate predictions using the `predict_proba()` function in `sklearn`. We need probabilistic instead of binary predictions to compute the ROC thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf_tree.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute false positive rate, true positive rate and thresholds defining ROC curve\n",
    "# (note: these values define the points at which the ROC curve has a kink)\n",
    "fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, y_pred_proba, pos_label = 1)\n",
    "\n",
    "print('False positive rates: {}\\n'.format(fpr_tree))\n",
    "print('True positive rates: {}\\n'.format(tpr_tree))\n",
    "print('Thresholds: {}\\n'.format(thresholds_tree))\n",
    "\n",
    "# Accuracy \n",
    "print('Accuracy:'.ljust(25) + str(acc_tree))\n",
    "\n",
    "# Compute and show area under the ROC curve\n",
    "roc_auc_tree = auc(fpr_tree, tpr_tree)\n",
    "print ('Area under curve (AUC):'.ljust(25) + str(roc_auc_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Plot the ROC curve. Remember: the ROC curve has the false positive rate on the x-axis and the true positive rate on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "\n",
    "plt.plot(fpr_tree, tpr_tree, lw = 2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.title('ROC curve for Classification Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compare classification tree to random forest model\n",
    "\n",
    "Random Forests are a model frequently applied in data science applications in business. Hence, let's see how they perform for this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Fit a random forest model. What's the optimal number of trees/estimators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune n_estimators parameter in the range(50, 251, 25)\n",
    "\n",
    "tuned_parameters = [{'n_estimators': range(50, 251, 25)}]\n",
    "\n",
    "clf_forest = GridSearchCV(RandomForestClassifier(random_state = SEED), tuned_parameters, cv = 5, scoring = 'accuracy')\n",
    "clf_forest.fit(X_train, y_train)\n",
    "\n",
    "# Look at the best parameters\n",
    "clf_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the optimal number of trees\n",
    "\n",
    "best_n_estimators = clf_forest.best_params_['n_estimators']\n",
    "best_n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Assess the model on the test set. What accuracy do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing best performing classifier tree on test set (baseline AUC is approx. 0.94)\n",
    "\n",
    "# Fit with the best number of estimators\n",
    "clf_randomForest = RandomForestClassifier(n_estimators = best_n_estimators, random_state=SEED)\n",
    "clf_randomForest.fit(X_train, y_train)\n",
    "\n",
    "# Compute accuracy on test set \n",
    "y_pred = clf_randomForest.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:'.ljust(25) + str(acc_rf))\n",
    "\n",
    "# AUC ROC\n",
    "y_predProba = clf_randomForest.predict_proba(X_test)[:, 1]\n",
    "fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, y_predProba, pos_label = 1)\n",
    "roc_auc_rf = auc(fpr_tree, tpr_tree)\n",
    "print ('Area under curve (AUC):'.ljust(25) + str(roc_auc_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SUMMARY OF ACCURACY AND AUC VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width   = 35\n",
    "models  = ['Decision Tree ACC', 'Random Forest ACC', 'Decision Tree AUC', 'Random Forest AUC']\n",
    "results = [acc_tree, acc_rf, roc_auc_tree, roc_auc_rf]\n",
    "print('', '=' * width, '\\n', 'Summary of ACC and AUC Scores'.center(width), '\\n', '=' * width)  \n",
    "for i in range(len(models)):\n",
    "    if i == 2: print()\n",
    "    print(models[i].center(width-8), '{0:.4f}'.format(results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
