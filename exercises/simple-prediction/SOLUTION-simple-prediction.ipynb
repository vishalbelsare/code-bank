{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Simple Prediction**: Linear and Logit Models (SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:  [https://github.com/d-insight/code-bank.git](https://github.com/d-insight/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we consider a simple linear prediction problem. Given some toy data, we try to recover the parameters of a data generating process (DGP) and make predictions based on the fitted parameters. DGP is a fancy term referring to the process that generates the real-world data we want to model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical matrix operations\n",
    "import numpy as np    \n",
    "\n",
    "# Data science models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a data generating process (DGP)\n",
    "\n",
    "We simply define the linear DGP as a line of the form `y = m * x + b` with the following coefficients:\n",
    "\n",
    "- `m = 2`\n",
    "- `b = 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that implements our DGP\n",
    "\n",
    "def dgp(x):\n",
    "    \"\"\"\n",
    "    Linear DGP of the form y=mx+b, where m=2 and b=3\n",
    "    \n",
    "    Parameter: \n",
    "        x (float): input value\n",
    "    \n",
    "    Returns: \n",
    "        float: f(x) \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return 2 * x + 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data to use in the analysis below\n",
    "\n",
    "X = [1, 2, 3, 4, 5]\n",
    "\n",
    "y = []\n",
    "for x in X:\n",
    "    y.append(dgp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAIN EXERCISE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Predict the mean\n",
    "\n",
    "In the most simple form, our \"model\" simply predicts the mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1:** What is the mean of our outcome variable `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean\n",
    "\n",
    "y_mean = sum(y)/len(y)\n",
    "y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Plot the mean of `y` and the values of `X` and `y`. How well does the mean fit our DGP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean prediction\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y)\n",
    "plt.hlines(y_mean, xmin = min(X), xmax = max(X), colors='red')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this prediction does not fit well. The prediction is biased and has no variance. In fact, no prediction will have variance as the DGP has no noice/variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fit and predict a linear regression\n",
    "\n",
    "We now move beyond the mean. We fit a linear regression, which tries to estimate the coefficients for `m` and `b` that best fit the data generating process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data \n",
    "\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Fit a linear regression to `X` and `y`. Hint: do not forget to reshape the data into a two-dimensional shape. Why do we need to reshape our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression \n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: What is the R^2 score (i.e. the variance explained) for the above model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fit in terms of R^2 (i.e. variance explained)\n",
    "\n",
    "reg.score(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: What is the predicted value of `y` at `x = 6`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the DGP `y = m * x + b`, its true coefficients `m = 2` and `b = 3` and `x = 6`:\n",
    "\n",
    "`y = m * x + b`\n",
    "\n",
    "`y = 2 * x + 3`\n",
    "\n",
    "`y = 2 * 6 + 3`\n",
    "\n",
    "`y = 15`\n",
    "\n",
    "Let's validate this prediction with our fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict at x = 6\n",
    "\n",
    "reg.predict([[6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ADVANCED EXERCISE**\n",
    "\n",
    "*Optional.* If time permits and you feel comfortable with Python, continue with the advanced parts of this exercise below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 0**: What are the estimated coefficient and intercept values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate coefficient m\n",
    "\n",
    "reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate intercept b\n",
    "\n",
    "reg.intercept_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Set up a nonlinear DGP\n",
    "\n",
    "We now consider toy data that was generated by a *nonlinear* and *noisy* DGP. We want to predict two classes, where `y` equals `1` or `0`, that depend only on the value of `x`. \n",
    "\n",
    "Think back to the Credit Default demo. In this example, `y` stands for defaulting and `x` might stand for your amount of debt. In this oversimplified model, the more debt you have, the more likely you are to default. We would like predictions to lie in the continuous inerval `[0,1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Generate a Gaussian random sample for values of `X` centered around `0`. Inspect the first 10 values of `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples with seed = 0 and look at the first 10 values of X\n",
    "\n",
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.normal(size = n_samples)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: For all values `X > 0`, set `y` equal to `1` and `0` otherwise. Add some random noise to `X`. Hint: the numerical value of the boolean `True` is 1 and `False` is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y to 1 if X > 0\n",
    "\n",
    "y = X > 0\n",
    "\n",
    "# Convert boolean values to numbers\n",
    "\n",
    "y = y.astype(float)\n",
    "\n",
    "# Look at the first 10 entries of y\n",
    "\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some Gaussian noise around x = 0 and look the first 10 entries of X\n",
    "\n",
    "X = X + 0.2 * np.random.normal(size = n_samples)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Plot toy data and fit a linear classifier (linear regression)\n",
    "\n",
    "In this part, we simply plot the data. Plotting the data is key before fitting any statistical model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Plot `X` and `y` on a scatterplot. Will a linear classifier fit these data well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot with axis labels\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(min(X), max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Fit a linear regression and look at the intercept. Does the intercept have a reasonable values? Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression (hint: call .reshape(-1, 1) on X to tell NumPy that there's only one predictor )\n",
    "\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: Plot the linear regression fit. What can you say about predictions for very small/large `x`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear regression fit\n",
    "\n",
    "# np.linspace return evenly spaced numbers over a specified interval\n",
    "X_test = np.linspace(-2, 2, 100).reshape(-1, 1)\n",
    "\n",
    "# Option 1: manually extract the coefficients for the line y = m * x + b\n",
    "y_pred_linear = reg.coef_ * X_test + reg.intercept_\n",
    "\n",
    "# Option 2: use the .predict() function\n",
    "# y_pred_linear = reg.predict(X_test)\n",
    "\n",
    "plt.plot(X_test, y_pred_linear, linewidth=1)\n",
    "plt.scatter(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(min(X), max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the linear classifier is not a good fit. While the intercept looks plausible, the model predicts values outside the `[0,1]` range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Fit a nonlinear classifier (logistic regression)\n",
    "\n",
    "We now implement a nonlinear classifier, which should better fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Fit a logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the logistic regression\n",
    "\n",
    "logReg = LogisticRegression(solver='lbfgs').fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Plot the fitted function. Hint: apply the expit() function to your prediction. This will convert the predictions to an inverse sigmoid shape. How does this model fit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear regression fit\n",
    "\n",
    "# Option 1: manually extract the coefficients (uncomment line below)\n",
    "# y_pred_nonlinear = X_test * logReg.coef_ + logReg.intercept_\n",
    "# transorm prediction to the inverse of the logit function (uncomment line below)\n",
    "# y_pred_nonlinear = expit(y_pred_nonlinear)\n",
    "\n",
    "# Option 2: use the .predict() function\n",
    "y_pred_nonlinear = logReg.predict_proba(X_test)[:,1]\n",
    "\n",
    "plt.plot(X_test, y_pred_nonlinear, linewidth=1)\n",
    "plt.scatter(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(min(X), max(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
