{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DSFM Exercise**: Simple predictions - linear and logit models (SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creator: [Data Science for Managers - EPFL Program](https://www.dsfm.ch)  \n",
    "Source:  [https://github.com/dsfm-org/code-bank.git](https://github.com/dsfm-org/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we consider a simple linear prediction problem. Given some toy data, we try to recover the parameters of a data generating process (DGP) and make predictions based on the fitted parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numerical matrix operations\n",
    "import numpy as np    \n",
    "\n",
    "# data science models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Set up a linear DGP\n",
    "\n",
    "We simply define the linear DGP as a line of the form `y = m * x + b` with the following coefficients:\n",
    "\n",
    "- `m = 2`\n",
    "- `b = 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1:** What are the values of `y` at `x` equal to 1, 2, 3, 4 and 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that implements our DGP\n",
    "\n",
    "def dgp(x):\n",
    "    \"\"\"\n",
    "    Linear DGP of the form y=mx+b, where m=2 and b=3\n",
    "    \n",
    "    Parameter: \n",
    "        x (float): input value\n",
    "    \n",
    "    Returns: \n",
    "        float: f(x) \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return 2 * x + 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy data\n",
    "\n",
    "X = [1, 2, 3, 4, 5]\n",
    "\n",
    "y = []\n",
    "for x in X:\n",
    "    y.append(dgp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Use the mean to make a prediction\n",
    "\n",
    "In the most simple form, our \"model\" simply predicts the mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1:** Plot the values of X and y. Does this DGP have any noise/variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with axis labels\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2:** What is the mean of our outcome variable `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean\n",
    "\n",
    "y_mean = sum(y)/len(y)\n",
    "y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: How well does the mean fit our DGP? Plot the mean of `y` and the values of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean prediction\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y)\n",
    "plt.hlines(y_mean, xmin = min(X), xmax = max(X), colors='red')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this prediction does not fit well. The prediction is biased and has no variance. In fact, no prediction will have variance as the DGP has no noice/variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Fit a linear regression and predict\n",
    "\n",
    "We now move beyond the mean. We fit a linear regression, which tries to estimate the coefficients for `m` and `b` that best fit the data generating process from Part 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Fit a linear regression to `X` and `y`. Hint: do not forget to reshape the data into a two-dimensional shape. Why do we need to reshape our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the linear regression \n",
    "\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: What is the R^2 score? What are the estimated coefficient and intercept values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the fit in terms of R^2 (i.e. variance explained)\n",
    "\n",
    "reg.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate coefficient m\n",
    "\n",
    "reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate intercept b\n",
    "\n",
    "reg.intercept_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: What is the predicted value of `y` at `x = 6`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the DGP `y = m * x + b`, its true coefficients `m = 2` and `b = 3` and `x = 6`:\n",
    "\n",
    "`y = m * x + b`\n",
    "\n",
    "`y = 2 * x + 3`\n",
    "\n",
    "`y = 2 * 6 + 3`\n",
    "\n",
    "`y = 15`\n",
    "\n",
    "Let's validate this prediction with our fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict at x = 6\n",
    "\n",
    "reg.predict([[6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Set up a nonlinear DGP\n",
    "\n",
    "We now consider toy data that was generated by a *nonlinear* and *noisy* DGP. We want to predict two classes, where `y` equals `1` or `0`, that depend only on the value of `x`. \n",
    "\n",
    "Think back to the Credit Default demo. In this example, `y` stands for defaulting and `x` might stand for your amount of debt. In this oversimplified model, the more debt you have, the more likely you are to default. We would like predictions to lie in the continuous inerval `[0,1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Generate a Gaussian random sample for values of `X` centered around `0`. Inspect the first 10 values of `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random samples with seed = 0 and look at the first 10 values of X\n",
    "\n",
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.normal(size = n_samples)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: For all values `X > 0`, set `y` equal to `1` and `0` otherwise. Add some random noise to `X`. Hint: the numerical value of the boolean `True` is 1 and `False` is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set y to 1 if X > 0\n",
    "\n",
    "y = X > 0\n",
    "\n",
    "# convert boolean values to numbers\n",
    "\n",
    "y = y.astype(np.float)\n",
    "\n",
    "# look at the first 10 entries of y\n",
    "\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some Gaussian noise around x = 0 and look the first 10 entries of X\n",
    "\n",
    "X = X + 0.2 * np.random.normal(size = n_samples)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Plot toy data and fit a linear classifier (linear regression)\n",
    "\n",
    "In this part, we simply plot the data. Plotting the data is key before fitting any statistical model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Plot `X` and `y` on a scatterplot. Will a linear classifier fit these data well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot with axis labels\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(min(X), max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Fit a linear regression and look at the intercept. Does the intercept have a reasonable values? Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the linear regression (hint: call .reshape(-1, 1) on X to tell NumPy that there's only one predictor )\n",
    "\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: Plot the linear regression fit. What can you say about predictions for very small/large `x`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot linear regression fit\n",
    "\n",
    "# np.linspace return evenly spaced numbers over a specified interval\n",
    "X_test = np.linspace(-2, 2, 100).reshape(-1, 1)\n",
    "\n",
    "# Option 1: manually extract the coefficients for the line y = m * x + b\n",
    "y_pred_linear = reg.coef_ * X_test + reg.intercept_\n",
    "\n",
    "# Option 2: use the .predict() function\n",
    "# y_pred_linear = reg.predict(X_test)\n",
    "\n",
    "plt.plot(X_test, y_pred_linear, linewidth=1)\n",
    "plt.scatter(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(min(X), max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the linear classifier is not a good fit. While the intercept looks plausible, the model predicts values outside the `[0,1]` range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Fit a nonlinear classifier (logistic regression)\n",
    "\n",
    "We now implement a nonlinear classifier, which should better fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Fit a logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logistic regression\n",
    "\n",
    "logReg = LogisticRegression(solver='lbfgs').fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Plot the fitted function. Hint: apply the expit() function to your prediction. This will convert the predictions to an inverse sigmoid shape. How does this model fit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot linear regression fit\n",
    "\n",
    "# Option 1: manually extract the coefficients (uncomment line below)\n",
    "# y_pred_nonlinear = X_test * logReg.coef_ + logReg.intercept_\n",
    "# transorm prediction to the inverse of the logit function (uncomment line below)\n",
    "# y_pred_nonlinear = expit(y_pred_nonlinear)\n",
    "\n",
    "# Option 2: use the .predict() function\n",
    "y_pred_nonlinear = logReg.predict_proba(X_test)[:,1]\n",
    "\n",
    "plt.plot(X_test, y_pred_nonlinear, linewidth=1)\n",
    "plt.scatter(X, y)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(min(X), max(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
