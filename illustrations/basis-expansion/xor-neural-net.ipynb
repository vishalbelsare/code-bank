{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Solve the XOR Problem with a Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:  [https://github.com/d-insight/code-bank.git](https://github.com/d-insight/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustration shows the solving of the non-linear XOR problem with a neural network. The illustration can be used in conjunction with showing alternative methods, such as basis expansions, for warping and then separating a space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 0**: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "# Special code to ignore un-important warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all constants\n",
    "\n",
    "# Part 1\n",
    "EPOCHS_1 = 20000\n",
    "\n",
    "# Part 2\n",
    "N                     = 100\n",
    "STD                   = 0.30\n",
    "HIDDEN_LAYER1_NEURONS = 4\n",
    "EPOCHS_2              = 500\n",
    "FIGSIZE               = (10, 10)\n",
    "FONTSIZE              = 16\n",
    "PLOT_X1_LABEL         = '\\nNo A                              Yes A'\n",
    "PLOT_X2_LABEL         = '\\nNo B                              Yes B'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1**: Minimum number of layers and nodes for XOR\n",
    "\n",
    "A fundamental question when designing neural networks is how many hidden layers and neurons per hidden layer to use. We explore this question in the context of the XOR problem. Note how we require a high number of epochs given the scarce training data. Here is a useful complementary article explaining the intuition: https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e\n",
    "\n",
    "Will the network always achieve 100% accuracy? No, this depends on the randomly initialized weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate toy data\n",
    "FEATURES = np.array([[0,0], [0,1], [1,0], [1,1], [0,0], [0,1], [1,0], [1,1]], \"float32\")\n",
    "LABELS   = np.array([ [0],   [1],   [1],   [0] ,  [0],   [1],   [1],   [0]],  \"float32\")  # must be same order\n",
    "\n",
    "# define Model:  Keras Sequential Fully-Connected Feed-Forward Network\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim = 2, activation = 'sigmoid', kernel_initializer = 'glorot_uniform'))  # Hidden Layer\n",
    "model.add(Dense(1, activation = 'sigmoid', kernel_initializer = 'glorot_uniform'))                 # Output Layer\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'nadam', metrics = ['binary_accuracy'])\n",
    "\n",
    "# fit Model\n",
    "model.fit(FEATURES, LABELS, epochs = EPOCHS_1, verbose = 0)\n",
    "loss, accuracy = model.evaluate(FEATURES, LABELS, verbose = 0)\n",
    "print('Loss: {} - Accuracy: {}\\n'.format(round(loss, 4), accuracy))\n",
    "\n",
    "# Predict Outcome\n",
    "predictions = model.predict(FEATURES).round()\n",
    "for i in range(len(LABELS)):\n",
    "    print('Label', LABELS[i], '  ', 'Prediction',predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**: Fuzzy XOR\n",
    "\n",
    "We now generate a fuzzy XOR problem, where the classes can overlap. The purpose of this demo is to show how Keras can be used to classify a quasi-XOR relationship with fuzzy and dispersed data.  The data is dispersed around 0 and 1 in the respective region depending on STD dispersion param; if STD is large, there can be overlap between classes.\n",
    "\n",
    "There are four regions of similarity in outcome values:\n",
    "\n",
    "        -----------\n",
    "        | UL | UR |\n",
    "        -----------\n",
    "        | BL | BR |\n",
    "        -----------\n",
    "\n",
    "    There are two factors (of two dimensions):\n",
    "\n",
    "        Factor A = -1 in the BL region\n",
    "        Factor A =  1 in the BR region\n",
    "        Factor B = -1 in the BL region\n",
    "        Factor B =  1 in the UL region\n",
    "        in an XOR(A,B) relationship, the observations are -1 in the UR region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Data Variables -----------------------------------------------------------------------\n",
    "Y  = []\n",
    "X1 = []\n",
    "X2 = []\n",
    "COLORS = []\n",
    "\n",
    "# Generate data -------------------------------------------------------------------------------\n",
    "for i in range(N):\n",
    "\n",
    "    # Failure by neither (left bottom)\n",
    "    Y.append(0)\n",
    "    COLORS.append('red')\n",
    "    X1.append(np.random.normal(loc=0.0, scale=STD))\n",
    "    X2.append(np.random.normal(loc=0.0, scale=STD))\n",
    "\n",
    "    # Success by A (right bottom)\n",
    "    Y.append(1)\n",
    "    COLORS.append('green')\n",
    "    X1.append(np.random.normal(loc=1.0, scale=STD))\n",
    "    X2.append(np.random.normal(loc=0.0, scale=STD))\n",
    "\n",
    "    # Success by B (left upper)\n",
    "    Y.append(1)\n",
    "    COLORS.append('green')\n",
    "    X1.append(np.random.normal(loc=0.0, scale=STD))\n",
    "    X2.append(np.random.normal(loc=1.0, scale=STD))\n",
    "\n",
    "    # Failure by both (right upper)\n",
    "    Y.append(0)\n",
    "    COLORS.append('red')\n",
    "    X1.append(np.random.normal(loc=1.0, scale=STD))\n",
    "    X2.append(np.random.normal(loc=1.0, scale=STD))\n",
    "\n",
    "DATA = np.array(list(zip(X1, X2)))\n",
    "Y    = np.array(Y)\n",
    "\n",
    "\n",
    "# Plot the data in 2-D  ------------------------------------------------------------------------\n",
    "fig = plt.figure(1, figsize=FIGSIZE)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "ax.set_xlabel(PLOT_X1_LABEL, fontsize = FONTSIZE)\n",
    "ax.set_ylabel(PLOT_X2_LABEL, fontsize = FONTSIZE)\n",
    "for i in range(len(X1)):\n",
    "    ax.plot(X1[i], X2[i], Y[i], c=COLORS[i], marker='o', markersize=10)\n",
    "plt.hlines(0.5, xmin = min(X1), xmax = max(X1), colors='black', linewidth=1)\n",
    "plt.vlines(0.5, ymin = min(X2), ymax = max(X2), colors='black', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "print('Neural network training.\\n')\n",
    "\n",
    "# Define Model: Keras sequential feed-forward neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(HIDDEN_LAYER1_NEURONS, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid')) # Final output layer with one resulting neuron\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "# Fit\n",
    "model.fit(DATA, Y, epochs=EPOCHS_2, verbose=0)\n",
    "loss, accuracy = model.evaluate(DATA, Y, verbose = 0)\n",
    "print('Loss: {} - Accuracy: {}\\n'.format(round(loss, 4), accuracy))\n",
    "\n",
    "# Predict\n",
    "Y_HAT = [int(round(value[0])) for value in model.predict(DATA)]\n",
    "HUE   = []\n",
    "MARK  = []\n",
    "\n",
    "for i in range(len(Y_HAT)):\n",
    "    if bool(Y_HAT[i] == Y[i]):\n",
    "        MARK.append('o')\n",
    "        HUE.append(COLORS[i])\n",
    "    else:\n",
    "        MARK.append('x')\n",
    "        HUE.append('red' if COLORS[i]=='green' else 'green')\n",
    "\n",
    "# Plot Results\n",
    "fig = plt.figure(2, figsize=FIGSIZE)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "ax.set_xlabel(PLOT_X1_LABEL, fontsize = FONTSIZE)\n",
    "ax.set_ylabel(PLOT_X2_LABEL, fontsize = FONTSIZE)\n",
    "for i in range(len(X1)):\n",
    "    ax.plot(X1[i], X2[i], Y_HAT[i], c=HUE[i], marker=MARK[i], markersize=10)\n",
    "plt.hlines(0.5, xmin = min(X1), xmax = max(X1), colors='black', linewidth=1)\n",
    "plt.vlines(0.5, ymin = min(X2), ymax = max(X2), colors='black', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
