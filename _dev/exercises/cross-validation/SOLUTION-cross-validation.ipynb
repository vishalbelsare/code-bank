{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DSFM Exercise**: Cross-validation - Resampling to Evaluate Models (SOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creator: [Data Science for Managers - EPFL Program](https://www.dsfm.ch)  \n",
    "Source:  [https://github.com/dsfm-org/code-bank.git](https://github.com/dsfm-org/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Cross-validation is a resampling procedure to evaluate statistical models based on a limited dataset. Computing model performance using cross-validation often results in more reliable, less biased, and less optimistic estimates of how well our model performs on unseen data.\n",
    "\n",
    "k-fold cross-validation splits the dataset into *k* groups, which are used as training or testing datasets in an alternating manner. The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into *k* groups\n",
    "3. For each unique group:\n",
    "    1. Take the first group as test data\n",
    "    2. Take the remaining groups as a training data\n",
    "    3. Fit a model on the training data and evaluate it on the test data\n",
    "    4. Retain the evaluation score; discard the model\n",
    "4. Summarize model performance using the sample of evaluation scores collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kfold.png\" width=\"800\" height=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Image source: EPFL TIS Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It follows that when e.g. *k=5*, we refer to the procedure as five-fold cross-validation (see image right above). Selecting the right value for *k* is important. As a starting point, values for *k* between 3 and 10 (inclusive) tend to work well. We want to make sure that the resulting train/test split is representative of the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 0**: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use tha array data structure from NumPy\n",
    "import numpy as np\n",
    "\n",
    "# sklearn has k-fold cross-validation already implemented\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAIN EXERCISE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1**: Make up some toy data\n",
    "\n",
    "First, we come up with some toy observations that make it easier to follow the k-fold cross-validation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Assign an array of the following observations to a variable named `data`:\n",
    "\n",
    "`[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data\n",
    "data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**: Set up cross-validation schema\n",
    "\n",
    "Next, we set up the k-fold cross-validation schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Use the `KFold` function from `sklearn` with `k=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation schema\n",
    "kfold = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3**: Apply cross-validation\n",
    "\n",
    "Finally, show the train/test splits for each of the folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Print the train/test splits for all *k* folds. Why are the observations split the way they are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data: ', data)\n",
    "print()\n",
    "\n",
    "# Show train/test splits\n",
    "for train, test in kfold.split(data):\n",
    "    print('Train: %s, Test: %s' % (data[train], data[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Further reading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [A gentle introduction to k-fold cross-validation](https://machinelearningmastery.com/k-fold-cross-validation/) on machinelearningmastery.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
