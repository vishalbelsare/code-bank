{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DSFM Exercise**: Sentiment Analysis - NLP, Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creator: [Data Science for Managers - EPFL Program](https://www.dsfm.ch)  \n",
    "Source:  [https://github.com/dsfm-org/code-bank.git](https://github.com/dsfm-org/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a challenging subject in machine learning. People express their emotions in a way that can be very ambiguous for both humans and computers. In this demo, we analyze sentiments of a set of IMDB movie reviews. The dataset consists of review texts as well as a binary sentiment label (1: positive, 0: negative). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://barnraisersllc.com/wp-content/uploads/2017/01/Sentiment-Analysis.jpg\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "Image source: http://barnraisersllc.com/wp-content/uploads/2017/01/Sentiment-Analysis.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source: *Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). \"Learning Word Vectors for Sentiment Analysis.\" The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 0**: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all import statements at the top of your notebook\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "# Data science packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection         import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble                import RandomForestClassifier\n",
    "from sklearn.pipeline                import Pipeline\n",
    "from sklearn.model_selection         import train_test_split\n",
    "\n",
    "# Neural networks\n",
    "from tensorflow.keras.models                 import Sequential, load_model\n",
    "from tensorflow.keras.layers                 import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text     import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Text processing packages\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem   import SnowballStemmer\n",
    "from gensim.models import doc2vec, word2vec\n",
    "\n",
    "# Visualization packages\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants \n",
    "\n",
    "# Set a seed for replication\n",
    "SEED = 10\n",
    "\n",
    "# Set performance metric\n",
    "SCORE = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested cross validation helper function\n",
    "def nested_cv(X, y, est_pipe, p_grid, p_score, n_splits_inner = 3, n_splits_outer = 3, n_cores = 1, seed = 0):\n",
    "\n",
    "    # Cross-validation schema for inner and outer loops (stratified if it is a classification)\n",
    "    inner_cv = KFold(n_splits = n_splits_inner, shuffle = True, random_state = seed)\n",
    "    outer_cv = KFold(n_splits = n_splits_outer, shuffle = True, random_state = seed)\n",
    "    \n",
    "    # Grid search to tune hyper parameters\n",
    "    est = GridSearchCV(estimator = est_pipe, param_grid = p_grid, cv = inner_cv, scoring = p_score, n_jobs = n_cores)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_scores = cross_val_score(estimator = est, X = X, y = y, cv = outer_cv, scoring = p_score, n_jobs = n_cores)\n",
    "    \n",
    "    print('Average score: %0.4f (+/- %0.4f)' % (nested_scores.mean(), nested_scores.std() * 1.96))\n",
    "    \n",
    "    return nested_scores.mean(), nested_scores.std() * 1.96\n",
    "\n",
    "# Define a function to split a review into clean list of words\n",
    "def review_to_wordlist(review):\n",
    "    \n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "   \n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if not w in stops]\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    \n",
    "    return(words)\n",
    "\n",
    "# Define a function to split a review into parsed sentences, where each sentence is a word list\n",
    "def review_to_sentences(review, tokenizer):\n",
    "    \n",
    "    raw_sentences = tokenizer.tokenize(review.strip())  \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:      \n",
    "        if len(raw_sentence) > 0:           \n",
    "            sentences.append( review_to_wordlist( raw_sentence ))\n",
    "   \n",
    "    return sentences\n",
    "\n",
    "# Function to average all of the word vectors in a given paragraph\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    nwords = 0.\n",
    "     \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "# Given a set of reviews (each one a list of words), calculate \n",
    "# the average feature vector for each one and return a 2D numpy array\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype='float32')\n",
    "     \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       \n",
    "       # Print a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print ('Review %d of %d' % (counter, len(reviews)))\n",
    "       \n",
    "        # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "       \n",
    "        # Increment the counter\n",
    "        counter = counter + 1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1**: EDA\n",
    "\n",
    "In the first part, we load the `sentiment_data.tsv` dataset. The dataset consists of `id`, `sentiment`, and `review` columns.\n",
    "\n",
    "Hint: This is a *tab*-separated file, but we can still use pandas' `read_csv` function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Load the data. What shape does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Extract the observation at index 0. How does the review text look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: Plot the distribution of the target and plot a word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 4**: Check for missing values and drop rows containing missing values (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**: Text pre-processing\n",
    "\n",
    "In the second part, we pre-process the raw review text in the following steps:\n",
    "\n",
    "1. Remove HTML tags\n",
    "2. Keep only alphabetical terms\n",
    "3. Lowercase all words\n",
    "4. Remove stop words\n",
    "5. Stem words\n",
    "\n",
    "IMPORTANT: Use the review at index 0 for each step to see how it changes. We will pre-process all reviews in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Remove HTML tags with the `BeautifulSoup` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Keep only alphabetical terms/words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: Lowercase all words and separate text by blank spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 4**: Remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 5**: Stem all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 6**: Consolidate all steps into a single function called `review_to_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 7**: Pre-process all reviews with the new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3**: Feature Extraction using TFIDF\n",
    "\n",
    "In this short part, we transform the cleaned text into TFIDF representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Transform cleaned reviews to TFIDF using the 5000 most frequent words in the corpus. What shape will the new representation have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Print the TFIDF values of the first 10 words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 4**: Binary classification using Random Forest with TFIDF Features\n",
    "\n",
    "In this part, we will run a binary classification using Random Forest and the TFIDF features to predict the binary sentiment label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Extract the target vector from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Fit a `RandomForestClassifier` to our data and test different parameter values for `n_estimators` (e.g. from 10 to 50). \n",
    "\n",
    "What nested cross validated accuracy do you get? How long does it take to test the different parameter values?\n",
    "\n",
    "Hint 1: Use the `%%time` magic command at the beginning of the cell for timing.\n",
    "\n",
    "Hint 2: Use the `nested_cv` helper function defined at the very top of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 5**: Word Vectors - Word2Vec\n",
    "\n",
    "A popular vectorization method for words is a technique known as Word2Vec, which is implemented in the `gensim` library. \n",
    "\n",
    "In Word2Vec each word is assigned a low-dimensional vector which is learnt under the assumption that words that are close to each other in a document are semantically related. Word2Vec can be used as a base for vectorize documents in low dimensions. You can read more about it here: https://cs224d.stanford.edu/lectures/CS224d-Lecture2.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Extract all sentences using the `punkt` tokenizer in the `nltk` package. How many sentences are in the corpus?\n",
    "\n",
    "Hint: Use the `review_to_sentences` helper function defined at the very top of this notebook to convert reviews to sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Train the word vectors using the `Word2Vec` function in the `gensim` package. Generate word vectors with 300 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: Investigate how words relate to each other using the `doesnt_match` and `most_similar` functions on the trained Word2Vec model. What's the most similar word to \"man\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph vectors - Average Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the word vectors show good semantical properties, using them to get the same sort of properties from sentences is not straight forward. The simplest solution is to average word vectors of a document to come up with the same dimensional paragraph vector.\n",
    "\n",
    "Hint 1: Use the `review_to_wordlist` helper function defined at the very top of this notebook. \n",
    "\n",
    "Hint 2: Use the `getAvgFeatureVecs` helper function defined at the very top of this notebook to average word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 4**: Fit a `RandomForestClassifier` to our data and test different parameter values for `n_estimators` (e.g. from 10 to 50). \n",
    "\n",
    "What nested cross validated accuracy do you get? How long does it take to test the different parameter values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 6**: Document Vectors - Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another solution to obtain review vectors is to obtain them directly. Paragraph Vectors are treating each document as a word itself and obtains their vectors directly. You can read more about it here: https://cs.stanford.edu/~quocle/paragraph_vector.pdf . Again, the `gensim` library implements this method in the `doc2vec` class.\n",
    "\n",
    "The first two cells below get rid of some \"housekeeping\" to prepare the data. Make sure the variable names match with your variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec needs each review to be tagged with some sort of ids\n",
    "# Here we tag each review with the 'id' field\n",
    "\n",
    "tagged_clean_data_reviews = []\n",
    "for uid, review in zip(data['id'], clean_data_reviews):\n",
    "    tagged_clean_data_reviews.append(doc2vec.TaggedDocument(words=review, tags=['%s' % uid[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of tagging\n",
    "\n",
    "tagged_clean_data_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1**: Train the document vectors using the `Doc2Vec` function in the `gensim` package. Generate document vectors with 300 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2**: Investigate how documents relate to each other using the `docvecs.similarity` function on the trained Doc2Vec model. How similar are documents d1 = '7759_3' and d2 = '5814_8'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 3**: Fit a `RandomForestClassifier` to our data and test different parameter values for `n_estimators` (e.g. from 10 to 50). Hint: use the `linspace` function in the `numpy` package to generate evenly spaced numbers in a given interval.\n",
    "\n",
    "What nested cross validated accuracy do you get? How long does it take to test the different parameter values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SUMMARY OF ACCURACY SCORES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width       = 50\n",
    "models      = ['Baseline', 'Random Forest', 'Random Forest + word2vec', 'Random Forest + doc2vec']\n",
    "result_acc  = [0.5, acc_rf, acc_rfW2V, acc_rfD2V]\n",
    "result_std  = [0,   std_rf, std_rfW2V, std_rfD2V]\n",
    "\n",
    "print('', '=' * width, '\\n', 'Summary of Accuracy Scores'.center(width), '\\n', '=' * width)  \n",
    "for i in range(len(models)):\n",
    "    print(models[i].center(width-18), '{0:.4f}'.format(result_acc[i]), '+/-{0:.4f}'.format(result_std[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
